{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.get_data import data_ingestion\n",
    "\n",
    "from src.features.transform import preprocess_data\n",
    "from src.models.train import train_model\n",
    "from src.models.validate import validate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/raw/ATRGFNP_hist.csv\n",
      "Processing 2161 records from 2019-03-26 00:00:00 to 2025-08-27 00:00:00\n",
      "\n",
      "Data saved to: data/raw/ATRGFNP_hist_with_buy_signals.csv\n"
     ]
    }
   ],
   "source": [
    "data_ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 19:57:42 | INFO     | Starting data preprocessing pipeline at            2025-08-30 19:57:42\n",
      "2025-08-30 19:57:42 | INFO     | Reading input data from CSV file\n",
      "2025-08-30 19:57:42 | SUCCESS  | Data loaded successfully: 2161 rows,             12 columns (took 0.01s)\n",
      "2025-08-30 19:57:42 | INFO     | Starting feature engineering for multiple timeframes\n",
      "2025-08-30 19:57:42 | INFO     | Processing 5 timeframes: [3, 7, 14, 21, 30] days\n",
      "2025-08-30 19:57:42 | INFO     | 3-day features completed: 10            features created (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | 7-day features completed: 10            features created (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | 14-day features completed: 10            features created (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | 21-day features completed: 10            features created (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | 30-day features completed: 10            features created (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | Combining all engineered features\n",
      "2025-08-30 19:57:42 | SUCCESS  | Feature combination completed: 50             total engineered features (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | Merging original data with engineered features\n",
      "2025-08-30 19:57:42 | SUCCESS  | Data merge completed: 2161 rows,             62 columns (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | Starting data cleaning process\n",
      "2025-08-30 19:57:42 | INFO     | Data cleaning completed: removed 60             rows (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | Starting train/test split process\n",
      "2025-08-30 19:57:42 | SUCCESS  | Temporal split completed (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | Defining feature columns\n",
      "2025-08-30 19:57:42 | SUCCESS  | Feature selection completed: 56 features identified\n",
      "2025-08-30 19:57:42 | INFO     | Separating features and targets\n",
      "2025-08-30 19:57:42 | SUCCESS  | Feature/target separation completed (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | Starting feature scaling process\n",
      "2025-08-30 19:57:42 | SUCCESS  | Feature scaling completed (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | Creating complete scaled dataframes\n",
      "2025-08-30 19:57:42 | INFO     | Saving fitted scaler\n",
      "2025-08-30 19:57:42 | SUCCESS  | Scaler saved to: data/processed/scaler.pkl (took 0.00s)\n",
      "2025-08-30 19:57:42 | INFO     | DATA PREPROCESSING PIPELINE COMPLETED\n",
      "2025-08-30 19:57:42 | INFO     | Total processing time: 0.05 seconds (0.0 minutes)\n",
      "2025-08-30 19:57:42 | INFO     | Original dataset: 2161 rows\n",
      "2025-08-30 19:57:42 | INFO     | After cleaning: 2101 rows\n",
      "2025-08-30 19:57:42 | INFO     | Training features shape: (1680, 56)\n",
      "2025-08-30 19:57:42 | INFO     | Test features shape: (421, 56)\n",
      "2025-08-30 19:57:42 | INFO     | Total engineered features: 56\n",
      "2025-08-30 19:57:42 | INFO     | Pipeline completed at 2025-08-30 19:57:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating technical features for 3 days period...\n",
      "‚úì Added 10 features for 3-day period\n",
      "Calculating technical features for 7 days period...\n",
      "‚úì Added 10 features for 7-day period\n",
      "Calculating technical features for 14 days period...\n",
      "‚úì Added 10 features for 14-day period\n",
      "Calculating technical features for 21 days period...\n",
      "‚úì Added 10 features for 21-day period\n",
      "Calculating technical features for 30 days period...\n",
      "‚úì Added 10 features for 30-day period\n",
      "Prev shape 2161\n",
      "Removed rows 60\n",
      "Train set: 1680           rows (80.0%)\n",
      "Test set: 421           rows (20.0%)\n",
      "feature_cols:  ['navpu_value', 'price_change', 'ma_7', 'ma_30', 'rsi', 'future_return_7d', 'future_return_30d', 'pct_change_3d', 'ma_3d', 'support_3d', 'resistance_3d', 'ma_distance_3d', 'volatility_3d', 'price_vs_support_3d', 'price_vs_resistance_3d', 'ma_trend_3d', 'pct_change_7d', 'ma_7d', 'support_7d', 'resistance_7d', 'ma_distance_7d', 'sr_position_7d', 'volatility_7d', 'price_vs_support_7d', 'price_vs_resistance_7d', 'ma_trend_7d', 'pct_change_14d', 'ma_14d', 'support_14d', 'resistance_14d', 'ma_distance_14d', 'sr_position_14d', 'volatility_14d', 'price_vs_support_14d', 'price_vs_resistance_14d', 'ma_trend_14d', 'pct_change_21d', 'ma_21d', 'support_21d', 'resistance_21d', 'ma_distance_21d', 'sr_position_21d', 'volatility_21d', 'price_vs_support_21d', 'price_vs_resistance_21d', 'ma_trend_21d', 'pct_change_30d', 'ma_30d', 'support_30d', 'resistance_30d', 'ma_distance_30d', 'sr_position_30d', 'volatility_30d', 'price_vs_support_30d', 'price_vs_resistance_30d', 'ma_trend_30d']\n",
      "Total features: 56\n",
      "Target variable: buy\n",
      "\n",
      "Scaler saved to: data/processed/scaler.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           original_label  navpu_value  buy  buy_strength  price_change   \n",
       " date                                                                      \n",
       " 2019-05-14   May 14, 2019    -0.950510    0             0     -1.276976  \\\n",
       " 2019-05-15   May 15, 2019    -0.970127    0             0     -0.360147   \n",
       " 2019-05-16   May 16, 2019    -0.896869    0             0      1.201657   \n",
       " 2019-05-17   May 17, 2019    -0.910441    0             0     -0.255971   \n",
       " 2019-05-20   May 20, 2019    -0.912305    1             1     -0.062440   \n",
       " ...                   ...          ...  ...           ...           ...   \n",
       " 2024-05-29   May 29, 2024     2.421249    0             0     -0.602713   \n",
       " 2024-05-30   May 30, 2024     2.475326    0             0      0.466540   \n",
       " 2024-05-31   May 31, 2024     2.496791    0             0      0.164771   \n",
       " 2024-06-01    Jun 1, 2024     2.496791    1             1     -0.031515   \n",
       " 2024-06-02    Jun 2, 2024     2.496791    0             0     -0.031515   \n",
       " \n",
       "                 ma_7     ma_30       rsi    buy_reason  future_return_7d  ...   \n",
       " date                                                                      ...   \n",
       " 2019-05-14 -0.847962 -0.889320 -1.122156           NaN         -0.102762  ...  \\\n",
       " 2019-05-15 -0.876815 -0.884526 -1.059026           NaN          0.101976  ...   \n",
       " 2019-05-16 -0.887145 -0.878152 -0.772952           NaN         -0.275783  ...   \n",
       " 2019-05-17 -0.897357 -0.872042 -0.518248           NaN         -0.137412  ...   \n",
       " 2019-05-20 -0.907131 -0.868415 -0.688434  Near Support         -0.654693  ...   \n",
       " ...              ...       ...       ...           ...               ...  ...   \n",
       " 2024-05-29  2.493027  2.466813 -0.201940           NaN         -0.036785  ...   \n",
       " 2024-05-30  2.493157  2.479395  0.189968           NaN         -0.084712  ...   \n",
       " 2024-05-31  2.496935  2.492719  0.029843           NaN         -0.367579  ...   \n",
       " 2024-06-01  2.500714  2.506566  0.029843    DCA Signal         -0.367579  ...   \n",
       " 2024-06-02  2.504493  2.517933  0.029843           NaN         -0.367579  ...   \n",
       " \n",
       "             pct_change_30d    ma_30d  support_30d  resistance_30d   \n",
       " date                                                                \n",
       " 2019-05-14        0.318896 -0.889320    -0.844530       -0.997661  \\\n",
       " 2019-05-15        0.266902 -0.884526    -0.822547       -0.997661   \n",
       " 2019-05-16        0.408386 -0.878152    -0.822547       -0.997661   \n",
       " 2019-05-17        0.385134 -0.872042    -0.751486       -0.997661   \n",
       " 2019-05-20        0.151764 -0.868415    -0.708629       -0.997661   \n",
       " ...                    ...       ...          ...             ...   \n",
       " 2024-05-29        0.317083  2.466813     2.412248        2.453964   \n",
       " 2024-05-30        0.464479  2.479395     2.412248        2.453964   \n",
       " 2024-05-31        0.502212  2.492719     2.412248        2.453964   \n",
       " 2024-06-01        0.530274  2.506566     2.485111        2.453964   \n",
       " 2024-06-02        0.398219  2.517933     2.485111        2.453964   \n",
       " \n",
       "             ma_distance_30d  sr_position_30d  volatility_30d   \n",
       " date                                                           \n",
       " 2019-05-14        -0.448958        -0.485414       -0.434309  \\\n",
       " 2019-05-15        -0.571804        -0.771512       -0.528459   \n",
       " 2019-05-16        -0.230447        -0.098795       -0.626175   \n",
       " 2019-05-17        -0.328941        -0.588708       -0.746407   \n",
       " 2019-05-20        -0.355910        -0.955758       -0.807588   \n",
       " ...                     ...              ...             ...   \n",
       " 2024-05-29         0.089470         0.313090        0.099608   \n",
       " 2024-05-30         0.209324         0.672502        0.035013   \n",
       " 2024-05-31         0.233426         0.815170       -0.038445   \n",
       " 2024-06-01         0.194696         0.765485       -0.145928   \n",
       " 2024-06-02         0.163007         0.765485       -0.213224   \n",
       " \n",
       "             price_vs_support_30d  price_vs_resistance_30d  ma_trend_30d  \n",
       " date                                                                     \n",
       " 2019-05-14             -0.418281                -0.100215      0.316159  \n",
       " 2019-05-15             -0.624274                -0.183269      0.268956  \n",
       " 2019-05-16             -0.265966                 0.126900      0.398002  \n",
       " 2019-05-17             -0.683415                 0.069435      0.375689  \n",
       " 2019-05-20             -0.898213                 0.061544      0.171967  \n",
       " ...                          ...                      ...           ...  \n",
       " 2024-05-29             -0.313729                 0.393149      0.325898  \n",
       " 2024-05-30             -0.166772                 0.522583      0.457772  \n",
       " 2024-05-31             -0.108438                 0.573962      0.491129  \n",
       " 2024-06-01             -0.312162                 0.573962      0.514188  \n",
       " 2024-06-02             -0.312162                 0.573962      0.398842  \n",
       " \n",
       " [1680 rows x 60 columns],\n",
       "            original_label  navpu_value  buy  buy_strength  price_change   \n",
       " date                                                                      \n",
       " 2024-06-03    Jun 3, 2024     2.549560    0             0      0.449640  \\\n",
       " 2024-06-04    Jun 4, 2024     2.460396    0             0     -0.838902   \n",
       " 2024-06-05    Jun 5, 2024     2.434917    0             0     -0.264954   \n",
       " 2024-06-06    Jun 6, 2024     2.474878    0             0      0.335865   \n",
       " 2024-06-07    Jun 7, 2024     2.412213    0             0     -0.604576   \n",
       " ...                   ...          ...  ...           ...           ...   \n",
       " 2025-07-24   Jul 24, 2025     5.494121    0             0      0.387881   \n",
       " 2025-07-25   Jul 25, 2025     5.511801    0             0      0.083948   \n",
       " 2025-07-26   Jul 26, 2025     5.511801    0             0     -0.031515   \n",
       " 2025-07-27   Jul 27, 2025     5.511801    0             0     -0.031515   \n",
       " 2025-07-28   Jul 28, 2025     5.566116    0             0      0.322602   \n",
       " \n",
       "                 ma_7     ma_30       rsi buy_reason  future_return_7d  ...   \n",
       " date                                                                   ...   \n",
       " 2024-06-03  2.513198  2.531126  0.173082        NaN         -0.660619  ...  \\\n",
       " 2024-06-04  2.509832  2.541234 -0.738292        NaN         -0.671018  ...   \n",
       " 2024-06-05  2.511799  2.549363 -0.810439        NaN         -0.586644  ...   \n",
       " 2024-06-06  2.511735  2.556974 -0.238080        NaN         -0.760364  ...   \n",
       " 2024-06-07  2.499562  2.563853 -0.572385        NaN         -0.978322  ...   \n",
       " ...              ...       ...       ...        ...               ...  ...   \n",
       " 2025-07-24  5.471416  5.405065  0.808267        NaN          0.388712  ...   \n",
       " 2025-07-25  5.482509  5.429156  1.220176        NaN         -0.624808  ...   \n",
       " 2025-07-26  5.493603  5.449704  1.220176        NaN         -0.624808  ...   \n",
       " 2025-07-27  5.504696  5.468121  1.220176        NaN         -0.624808  ...   \n",
       " 2025-07-28  5.522813  5.488417  1.228217        NaN         -0.759832  ...   \n",
       " \n",
       "             pct_change_30d    ma_30d  support_30d  resistance_30d   \n",
       " date                                                                \n",
       " 2024-06-03        0.490252  2.531126     2.485111        2.469130  \\\n",
       " 2024-06-04        0.334742  2.541234     2.517364        2.469130   \n",
       " 2024-06-05        0.233156  2.549363     2.530492        2.469130   \n",
       " 2024-06-06        0.204284  2.556974     2.530492        2.469130   \n",
       " 2024-06-07        0.169734  2.563853     2.530492        2.469130   \n",
       " ...                    ...       ...          ...             ...   \n",
       " 2025-07-24        0.492414  5.405065     5.174863        5.544608   \n",
       " 2025-07-25        0.714439  5.429156     5.278946        5.563074   \n",
       " 2025-07-26        0.575856  5.449704     5.341536        5.563074   \n",
       " 2025-07-27        0.493881  5.468121     5.341536        5.563074   \n",
       " 2025-07-28        0.562105  5.488417     5.341536        5.619805   \n",
       " \n",
       "             ma_distance_30d  sr_position_30d  volatility_30d   \n",
       " date                                                           \n",
       " 2024-06-03         0.276524         1.069379       -0.275347  \\\n",
       " 2024-06-04        -0.005108         0.326045       -0.388662   \n",
       " 2024-06-05        -0.099812         0.076972       -0.494233   \n",
       " 2024-06-06        -0.007284         0.422897       -0.561456   \n",
       " 2024-06-07        -0.203767        -0.119572       -0.687253   \n",
       " ...                     ...              ...             ...   \n",
       " 2025-07-24         0.533002         1.069379        0.500357   \n",
       " 2025-07-25         0.520056         1.069379        0.454341   \n",
       " 2025-07-26         0.477873         1.069379        0.455840   \n",
       " 2025-07-27         0.440202         1.069379        0.472050   \n",
       " 2025-07-28         0.510764         1.069379        0.501180   \n",
       " \n",
       "             price_vs_support_30d  price_vs_resistance_30d  ma_trend_30d  \n",
       " date                                                                     \n",
       " 2024-06-03             -0.170181                 0.665510      0.481989  \n",
       " 2024-06-04             -0.498556                 0.452499      0.339405  \n",
       " 2024-06-05             -0.602477                 0.391632      0.248079  \n",
       " 2024-06-06             -0.495615                 0.487098      0.223971  \n",
       " 2024-06-07             -0.663192                 0.337391      0.190116  \n",
       " ...                          ...                      ...           ...  \n",
       " 2025-07-24              0.140849                 0.665510      0.491076  \n",
       " 2025-07-25             -0.038117                 0.665510      0.682359  \n",
       " 2025-07-26             -0.164583                 0.665510      0.562133  \n",
       " 2025-07-27             -0.164583                 0.665510      0.489748  \n",
       " 2025-07-28             -0.059331                 0.665510      0.551244  \n",
       " \n",
       " [421 rows x 60 columns])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 12:54:20 | INFO     | Configuration loaded from config.yaml\n",
      "2025-08-31 12:54:20 | INFO     | Starting model training at 2025-08-31 12:54:20\n",
      "2025-08-31 12:54:20 | INFO     | Experiment name: uitf_buy_classifier\n",
      "2025-08-31 12:54:20 | INFO     | Loading training data from data/processed/train.parquet\n",
      "2025-08-31 12:54:20 | INFO     | Training data loaded: 1680 rows, 60 columns\n",
      "2025-08-31 12:54:20 | INFO     | Columns: ['original_label', 'navpu_value', 'buy', 'buy_strength', 'price_change', 'ma_7', 'ma_30', 'rsi', 'buy_reason', 'future_return_7d', 'future_return_30d', 'pct_change_3d', 'ma_3d', 'support_3d', 'resistance_3d', 'ma_distance_3d', 'volatility_3d', 'price_vs_support_3d', 'price_vs_resistance_3d', 'ma_trend_3d', 'pct_change_7d', 'ma_7d', 'support_7d', 'resistance_7d', 'ma_distance_7d', 'sr_position_7d', 'volatility_7d', 'price_vs_support_7d', 'price_vs_resistance_7d', 'ma_trend_7d', 'pct_change_14d', 'ma_14d', 'support_14d', 'resistance_14d', 'ma_distance_14d', 'sr_position_14d', 'volatility_14d', 'price_vs_support_14d', 'price_vs_resistance_14d', 'ma_trend_14d', 'pct_change_21d', 'ma_21d', 'support_21d', 'resistance_21d', 'ma_distance_21d', 'sr_position_21d', 'volatility_21d', 'price_vs_support_21d', 'price_vs_resistance_21d', 'ma_trend_21d', 'pct_change_30d', 'ma_30d', 'support_30d', 'resistance_30d', 'ma_distance_30d', 'sr_position_30d', 'volatility_30d', 'price_vs_support_30d', 'price_vs_resistance_30d', 'ma_trend_30d']\n",
      "2025-08-31 12:54:20 | INFO     | Target distribution: {0: 957, 1: 723}\n",
      "2025-08-31 12:54:20 | INFO     | Dropped columns: ['original_label', 'buy_reason', 'buy_strength']\n",
      "2025-08-31 12:54:20 | INFO     | Features prepared: 56 features, 1680 samples\n",
      "2025-08-31 12:54:20 | INFO     | Feature columns: ['navpu_value', 'price_change', 'ma_7', 'ma_30', 'rsi', 'future_return_7d', 'future_return_30d', 'pct_change_3d', 'ma_3d', 'support_3d', 'resistance_3d', 'ma_distance_3d', 'volatility_3d', 'price_vs_support_3d', 'price_vs_resistance_3d', 'ma_trend_3d', 'pct_change_7d', 'ma_7d', 'support_7d', 'resistance_7d', 'ma_distance_7d', 'sr_position_7d', 'volatility_7d', 'price_vs_support_7d', 'price_vs_resistance_7d', 'ma_trend_7d', 'pct_change_14d', 'ma_14d', 'support_14d', 'resistance_14d', 'ma_distance_14d', 'sr_position_14d', 'volatility_14d', 'price_vs_support_14d', 'price_vs_resistance_14d', 'ma_trend_14d', 'pct_change_21d', 'ma_21d', 'support_21d', 'resistance_21d', 'ma_distance_21d', 'sr_position_21d', 'volatility_21d', 'price_vs_support_21d', 'price_vs_resistance_21d', 'ma_trend_21d', 'pct_change_30d', 'ma_30d', 'support_30d', 'resistance_30d', 'ma_distance_30d', 'sr_position_30d', 'volatility_30d', 'price_vs_support_30d', 'price_vs_resistance_30d', 'ma_trend_30d']\n",
      "2025-08-31 12:54:20 | INFO     | Target distribution: {0: 957, 1: 723}\n",
      "2025-08-31 12:54:20 | INFO     | Training 2 model types...\n",
      "2025-08-31 12:54:20 | INFO     | ==================================================\n",
      "2025-08-31 12:54:20 | INFO     | Training LogisticRegression\n",
      "2025-08-31 12:54:20 | INFO     | ==================================================\n",
      "2025-08-31 12:54:20 | INFO     | Training LogisticRegression with 3 parameter grids...\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Diane_1/Desktop/Github files/ATRGNFP_buy_classifier/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2025-08-31 12:54:39 | INFO     | LogisticRegression best CV score: 0.7930\n",
      "2025/08/31 12:54:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/31 12:54:43 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/08/31 12:54:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-08-31 12:54:43 | INFO     | Saved LogisticRegression model to models/LogisticRegression.pkl\n",
      "2025-08-31 12:54:43 | INFO     | LogisticRegression Results:\n",
      "2025-08-31 12:54:43 | INFO     |   CV Score: 0.7930\n",
      "2025-08-31 12:54:43 | INFO     |   Train Accuracy: 0.7810\n",
      "2025-08-31 12:54:43 | INFO     |   Train F1: 0.7360\n",
      "2025-08-31 12:54:43 | INFO     |   Best Parameters: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "2025-08-31 12:54:43 | INFO     |   Model saved to: models/LogisticRegression.pkl\n",
      "2025-08-31 12:54:43 | INFO     |   MLflow Run ID: 8997a7df533b4046931d8f12b1773755\n",
      "2025-08-31 12:54:43 | INFO     | üèÜ New best model: LogisticRegression (CV Score: 0.7930)\n",
      "2025-08-31 12:54:43 | INFO     | ==================================================\n",
      "2025-08-31 12:54:43 | INFO     | Training XGBoost\n",
      "2025-08-31 12:54:43 | INFO     | ==================================================\n",
      "2025-08-31 12:54:43 | INFO     | Training XGBoost with 1 parameter grids...\n",
      "2025-08-31 12:55:15 | INFO     | XGBoost best CV score: 0.9563\n",
      "2025/08/31 12:55:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/31 12:55:17 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/08/31 12:55:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-08-31 12:55:17 | INFO     | Saved XGBoost model to models/XGBoost.pkl\n",
      "2025-08-31 12:55:17 | INFO     | XGBoost Results:\n",
      "2025-08-31 12:55:17 | INFO     |   CV Score: 0.9563\n",
      "2025-08-31 12:55:17 | INFO     |   Train Accuracy: 0.9333\n",
      "2025-08-31 12:55:17 | INFO     |   Train F1: 0.9210\n",
      "2025-08-31 12:55:17 | INFO     |   Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.8}\n",
      "2025-08-31 12:55:17 | INFO     |   Model saved to: models/XGBoost.pkl\n",
      "2025-08-31 12:55:17 | INFO     |   MLflow Run ID: bf1300b111104a29a560123cf4f607c7\n",
      "2025-08-31 12:55:17 | INFO     | üèÜ New best model: XGBoost (CV Score: 0.9563)\n",
      "2025-08-31 12:55:17 | INFO     | Best model (XGBoost) also saved to models/best_model.pkl\n",
      "2025/08/31 12:55:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/31 12:55:19 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/08/31 12:55:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, feature_weights=None, gamma=None,\n",
       "               grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "               num_parallel_tree=None, ...),\n",
       " 'XGBoost',\n",
       " 0.9562626349176796)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 12:55:19 | INFO     | Configuration loaded from config.yaml\n",
      "2025-08-31 12:55:19 | INFO     | Starting model validation at 2025-08-31 12:55:19\n",
      "2025-08-31 12:55:19 | INFO     | Loading model from models/best_model.pkl\n",
      "2025-08-31 12:55:19 | INFO     | Model loaded successfully: XGBClassifier\n",
      "2025-08-31 12:55:19 | INFO     | Loading test data from data/processed/test.parquet\n",
      "2025-08-31 12:55:19 | INFO     | Test data loaded: 421 rows, 60 columns\n",
      "2025-08-31 12:55:19 | INFO     | Columns: ['original_label', 'navpu_value', 'buy', 'buy_strength', 'price_change', 'ma_7', 'ma_30', 'rsi', 'buy_reason', 'future_return_7d', 'future_return_30d', 'pct_change_3d', 'ma_3d', 'support_3d', 'resistance_3d', 'ma_distance_3d', 'volatility_3d', 'price_vs_support_3d', 'price_vs_resistance_3d', 'ma_trend_3d', 'pct_change_7d', 'ma_7d', 'support_7d', 'resistance_7d', 'ma_distance_7d', 'sr_position_7d', 'volatility_7d', 'price_vs_support_7d', 'price_vs_resistance_7d', 'ma_trend_7d', 'pct_change_14d', 'ma_14d', 'support_14d', 'resistance_14d', 'ma_distance_14d', 'sr_position_14d', 'volatility_14d', 'price_vs_support_14d', 'price_vs_resistance_14d', 'ma_trend_14d', 'pct_change_21d', 'ma_21d', 'support_21d', 'resistance_21d', 'ma_distance_21d', 'sr_position_21d', 'volatility_21d', 'price_vs_support_21d', 'price_vs_resistance_21d', 'ma_trend_21d', 'pct_change_30d', 'ma_30d', 'support_30d', 'resistance_30d', 'ma_distance_30d', 'sr_position_30d', 'volatility_30d', 'price_vs_support_30d', 'price_vs_resistance_30d', 'ma_trend_30d']\n",
      "2025-08-31 12:55:19 | INFO     | Target distribution: {0: 236, 1: 185}\n",
      "2025-08-31 12:55:19 | INFO     | Dropped columns: ['original_label', 'buy_reason', 'buy_strength']\n",
      "2025-08-31 12:55:19 | INFO     | Test features prepared: 56 features, 421 samples\n",
      "2025-08-31 12:55:19 | INFO     | Test target distribution: {0: 236, 1: 185}\n",
      "2025-08-31 12:55:19 | INFO     | Making predictions on test data...\n",
      "2025-08-31 12:55:19 | INFO     | Prediction probabilities obtained\n",
      "2025-08-31 12:55:19 | INFO     | ‚úÖ best_model accuracy (0.9287) meets threshold (0.8)\n",
      "2025/08/31 12:55:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/31 12:55:20 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/08/31 12:55:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-08-31 12:55:20 | INFO     | Validation summary saved to logs/validation_summary.csv\n",
      "2025-08-31 12:55:20 | INFO     | Validation completed successfully for best_model\n",
      "2025-08-31 12:55:20 | INFO     | Accuracy: 0.9287, Threshold met: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîç MODEL VALIDATION RESULTS - best_model\n",
      "============================================================\n",
      "Model: models/best_model.pkl\n",
      "Test Data: data/processed/test.parquet\n",
      "Test Samples: 421\n",
      "\n",
      "üìä Performance Metrics:\n",
      "  Accuracy:  0.9287 ‚úÖ\n",
      "  F1 Score:  0.9153\n",
      "  Recall:    0.8757\n",
      "  Precision: 0.9586\n",
      "  ROC AUC:   0.9631\n",
      "\n",
      "üìã Confusion Matrix:\n",
      "              Predicted\n",
      "               0    1\n",
      "  Actual  0   229    7\n",
      "          1    23  162\n",
      "\n",
      "üéØ Threshold Check:\n",
      "  ‚úÖ best_model accuracy (0.9287) meets threshold (0.8)\n",
      "\n",
      "‚è±Ô∏è  Validation completed in 0.03 minutes\n",
      "üìä MLflow Run ID: 72e3fe86f0ff47738b4f600bf53a135e\n",
      "üìÅ Artifacts saved to logs/ directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'best_model',\n",
       " 'validation_timestamp': '2025-08-31T12:55:19.420466',\n",
       " 'test_samples': 421,\n",
       " 'accuracy': 0.9287410926365796,\n",
       " 'f1_score': 0.9152542372881357,\n",
       " 'recall': 0.8756756756756757,\n",
       " 'precision': 0.9585798816568047,\n",
       " 'accuracy_threshold': 0.8,\n",
       " 'meets_threshold': True,\n",
       " 'warning_status': '‚úÖ best_model accuracy (0.9287) meets threshold (0.8)',\n",
       " 'validation_duration_minutes': 0.02580815,\n",
       " 'mlflow_run_id': '72e3fe86f0ff47738b4f600bf53a135e'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ UITF ML Pipeline - Local Testing\n",
      "This script tests your pipeline functions before Airflow deployment\n",
      "üß™ Testing UITF ML Pipeline Functions Locally\n",
      "============================================================\n",
      "\n",
      "üöÄ Step 1: Testing data_ingestion()\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 12:54:09 | INFO     | Starting data preprocessing pipeline at            2025-08-31 12:54:09\n",
      "2025-08-31 12:54:09 | INFO     | Reading input data from CSV file\n",
      "2025-08-31 12:54:09 | SUCCESS  | Data loaded successfully: 2161 rows,             12 columns (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | Starting feature engineering for multiple timeframes\n",
      "2025-08-31 12:54:09 | INFO     | Processing 5 timeframes: [3, 7, 14, 21, 30] days\n",
      "2025-08-31 12:54:09 | INFO     | 3-day features completed: 10            features created (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | 7-day features completed: 10            features created (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | 14-day features completed: 10            features created (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | 21-day features completed: 10            features created (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | 30-day features completed: 10            features created (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | Combining all engineered features\n",
      "2025-08-31 12:54:09 | SUCCESS  | Feature combination completed: 50             total engineered features (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | Merging original data with engineered features\n",
      "2025-08-31 12:54:09 | SUCCESS  | Data merge completed: 2161 rows,             62 columns (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | Starting data cleaning process\n",
      "2025-08-31 12:54:09 | INFO     | Data cleaning completed: removed 60             rows (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | Starting train/test split process\n",
      "2025-08-31 12:54:09 | SUCCESS  | Temporal split completed (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | Defining feature columns\n",
      "2025-08-31 12:54:09 | SUCCESS  | Feature selection completed: 56 features identified\n",
      "2025-08-31 12:54:09 | INFO     | Separating features and targets\n",
      "2025-08-31 12:54:09 | SUCCESS  | Feature/target separation completed (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | Starting feature scaling process\n",
      "2025-08-31 12:54:09 | SUCCESS  | Feature scaling completed (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | Creating complete scaled dataframes\n",
      "2025-08-31 12:54:09 | INFO     | Saving fitted scaler\n",
      "2025-08-31 12:54:09 | SUCCESS  | Scaler saved to: data/processed/scaler.pkl (took 0.00s)\n",
      "2025-08-31 12:54:09 | INFO     | DATA PREPROCESSING PIPELINE COMPLETED\n",
      "2025-08-31 12:54:09 | INFO     | Total processing time: 0.06 seconds (0.0 minutes)\n",
      "2025-08-31 12:54:09 | INFO     | Original dataset: 2161 rows\n",
      "2025-08-31 12:54:09 | INFO     | After cleaning: 2101 rows\n",
      "2025-08-31 12:54:09 | INFO     | Training features shape: (1680, 56)\n",
      "2025-08-31 12:54:09 | INFO     | Test features shape: (421, 56)\n",
      "2025-08-31 12:54:09 | INFO     | Total engineered features: 56\n",
      "2025-08-31 12:54:09 | INFO     | Pipeline completed at 2025-08-31 12:54:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/raw/ATRGFNP_hist.csv\n",
      "Processing 2161 records from 2019-03-26 00:00:00 to 2025-08-27 00:00:00\n",
      "\n",
      "Data saved to: data/raw/ATRGFNP_hist_with_buy_signals.csv\n",
      "‚úÖ data_ingestion() completed successfully\n",
      "\n",
      "üîÑ Step 2: Testing preprocess_data()\n",
      "----------------------------------------\n",
      "Calculating technical features for 3 days period...\n",
      "‚úì Added 10 features for 3-day period\n",
      "Calculating technical features for 7 days period...\n",
      "‚úì Added 10 features for 7-day period\n",
      "Calculating technical features for 14 days period...\n",
      "‚úì Added 10 features for 14-day period\n",
      "Calculating technical features for 21 days period...\n",
      "‚úì Added 10 features for 21-day period\n",
      "Calculating technical features for 30 days period...\n",
      "‚úì Added 10 features for 30-day period\n",
      "Prev shape 2161\n",
      "Removed rows 60\n",
      "Train set: 1680           rows (80.0%)\n",
      "Test set: 421           rows (20.0%)\n",
      "feature_cols:  ['navpu_value', 'price_change', 'ma_7', 'ma_30', 'rsi', 'future_return_7d', 'future_return_30d', 'pct_change_3d', 'ma_3d', 'support_3d', 'resistance_3d', 'ma_distance_3d', 'volatility_3d', 'price_vs_support_3d', 'price_vs_resistance_3d', 'ma_trend_3d', 'pct_change_7d', 'ma_7d', 'support_7d', 'resistance_7d', 'ma_distance_7d', 'sr_position_7d', 'volatility_7d', 'price_vs_support_7d', 'price_vs_resistance_7d', 'ma_trend_7d', 'pct_change_14d', 'ma_14d', 'support_14d', 'resistance_14d', 'ma_distance_14d', 'sr_position_14d', 'volatility_14d', 'price_vs_support_14d', 'price_vs_resistance_14d', 'ma_trend_14d', 'pct_change_21d', 'ma_21d', 'support_21d', 'resistance_21d', 'ma_distance_21d', 'sr_position_21d', 'volatility_21d', 'price_vs_support_21d', 'price_vs_resistance_21d', 'ma_trend_21d', 'pct_change_30d', 'ma_30d', 'support_30d', 'resistance_30d', 'ma_distance_30d', 'sr_position_30d', 'volatility_30d', 'price_vs_support_30d', 'price_vs_resistance_30d', 'ma_trend_30d']\n",
      "Total features: 56\n",
      "Target variable: buy\n",
      "\n",
      "Scaler saved to: data/processed/scaler.pkl\n",
      "‚úÖ preprocess_data() completed successfully\n",
      "\n",
      "üèãÔ∏è Step 3: Testing train_model()\n",
      "----------------------------------------\n",
      "‚ùå train_model() failed: No module named 'src.models.train_model'\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"/var/folders/4n/kh4b6v4x7l76wmq38rnl4c4r0000gn/T/ipykernel_2828/971604907.py\", line 60, in test_pipeline_functions\n",
      "    from src.models.train_model import train_model\n",
      "ModuleNotFoundError: No module named 'src.models.train_model'\n",
      "\n",
      "\n",
      "üîç Step 4: Testing validate_model()\n",
      "----------------------------------------\n",
      "‚ùå validate_model() failed: No module named 'src.models.validate_model'\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"/var/folders/4n/kh4b6v4x7l76wmq38rnl4c4r0000gn/T/ipykernel_2828/971604907.py\", line 76, in test_pipeline_functions\n",
      "    from src.models.validate_model import validate_model\n",
      "ModuleNotFoundError: No module named 'src.models.validate_model'\n",
      "\n",
      "\n",
      "============================================================\n",
      "üìä PIPELINE TEST SUMMARY\n",
      "============================================================\n",
      "  data_ingestion       ‚úÖ PASS\n",
      "  preprocess_data      ‚úÖ PASS\n",
      "  train_model          ‚ùå FAIL\n",
      "  validate_model       ‚ùå FAIL\n",
      "\n",
      "Overall: 2/4 steps successful\n",
      "üí• Some functions failed. Fix issues before deploying to Airflow.\n",
      "\n",
      "‚ùå Fix function issues before proceeding\n",
      "\n",
      "üìã AIRFLOW DEPLOYMENT CHECKLIST\n",
      "========================================\n",
      "Before deploying to Airflow, ensure:\n",
      "\n",
      "üìÅ File Structure:\n",
      "  ‚òê dags/simple_uitf_ml_dag.py exists\n",
      "  ‚òê dags/src/data/get_data.py exists\n",
      "  ‚òê dags/src/features/transform.py exists\n",
      "  ‚òê dags/src/models/train_model.py exists\n",
      "  ‚òê dags/src/models/validate_model.py exists\n",
      "\n",
      "üìä Data Files:\n",
      "  ‚òê data/processed/train.parquet exists\n",
      "  ‚òê data/processed/test.parquet exists\n",
      "  ‚òê config.yaml exists\n",
      "\n",
      "üê≥ Docker Setup:\n",
      "  ‚òê docker-compose.yml exists\n",
      "  ‚òê .env file exists\n",
      "  ‚òê Docker is running\n",
      "\n",
      "üß™ Testing:\n",
      "  ‚òê All pipeline functions tested locally\n",
      "  ‚òê DAG syntax validated\n",
      "  ‚òê No import errors\n",
      "\n",
      "üöÄ Deployment:\n",
      "  1. Run: docker compose up airflow-init\n",
      "  2. Run: docker compose up -d\n",
      "  3. Access: http://localhost:8080\n",
      "  4. Enable DAG: simple_uitf_ml_pipeline\n",
      "  5. Trigger manual run\n",
      "  6. Monitor in UI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nPIPELINE EXECUTION ORDER:\\n\\n1. data_ingestion()     ‚Üí Fetches raw data\\n   ‚Üì\\n2. preprocess_data()    ‚Üí Cleans and prepares data  \\n   ‚Üì  \\n3. train_model()        ‚Üí Trains ML models, saves best model\\n   ‚Üì\\n4. validate_model()     ‚Üí Validates on test data, logs to MLflow\\n\\nEach function should handle its own file I/O and return status information.\\nThe DAG will orchestrate the execution and handle errors/retries.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dag_locally.py - Test the DAG functions locally before deploying\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('dags/src')\n",
    "\n",
    "def test_pipeline_functions():\n",
    "    \"\"\"\n",
    "    Test all pipeline functions locally to ensure they work\n",
    "    before deploying to Airflow\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üß™ Testing UITF ML Pipeline Functions Locally\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = {\n",
    "        'data_ingestion': False,\n",
    "        'preprocess_data': False, \n",
    "        'train_model': False,\n",
    "        'validate_model': False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Test 1: Data Ingestion\n",
    "        print(\"\\nüöÄ Step 1: Testing data_ingestion()\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        from src.data.get_data import data_ingestion\n",
    "        data_ingestion()\n",
    "        results['data_ingestion'] = True\n",
    "        print(\"‚úÖ data_ingestion() completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå data_ingestion() failed: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    try:\n",
    "        # Test 2: Preprocessing\n",
    "        print(\"\\nüîÑ Step 2: Testing preprocess_data()\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        from src.features.transform import preprocess_data\n",
    "        preprocess_data()\n",
    "        results['preprocess_data'] = True\n",
    "        print(\"‚úÖ preprocess_data() completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå preprocess_data() failed: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    try:\n",
    "        # Test 3: Model Training\n",
    "        print(\"\\nüèãÔ∏è Step 3: Testing train_model()\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        from src.models.train_model import train_model\n",
    "        best_model, best_model_name, cv_score = train_model()\n",
    "        results['train_model'] = True\n",
    "        print(f\"‚úÖ train_model() completed successfully\")\n",
    "        print(f\"   Best model: {best_model_name}\")\n",
    "        print(f\"   CV score: {cv_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå train_model() failed: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    try:\n",
    "        # Test 4: Model Validation\n",
    "        print(\"\\nüîç Step 4: Testing validate_model()\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        from src.models.validate_model import validate_model\n",
    "        validation_result = validate_model()\n",
    "        results['validate_model'] = True\n",
    "        print(f\"‚úÖ validate_model() completed successfully\")\n",
    "        print(f\"   Test accuracy: {validation_result['accuracy']:.4f}\")\n",
    "        print(f\"   Meets threshold: {validation_result['meets_threshold']}\")\n",
    "        \n",
    "        if not validation_result['meets_threshold']:\n",
    "            print(f\"   ‚ö†Ô∏è Warning: {validation_result['warning_status']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå validate_model() failed: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä PIPELINE TEST SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total_steps = len(results)\n",
    "    successful_steps = sum(results.values())\n",
    "    \n",
    "    for step, success in results.items():\n",
    "        status = \"‚úÖ PASS\" if success else \"‚ùå FAIL\"\n",
    "        print(f\"  {step:20} {status}\")\n",
    "    \n",
    "    print(f\"\\nOverall: {successful_steps}/{total_steps} steps successful\")\n",
    "    \n",
    "    if successful_steps == total_steps:\n",
    "        print(\"üéâ All pipeline functions work! Ready for Airflow deployment.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"üí• Some functions failed. Fix issues before deploying to Airflow.\")\n",
    "        return False\n",
    "\n",
    "def simulate_airflow_execution():\n",
    "    \"\"\"\n",
    "    Simulate how the functions would run in Airflow DAG\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nüé≠ Simulating Airflow DAG Execution\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Simulate task context (like Airflow provides)\n",
    "    mock_context = {\n",
    "        'execution_date': datetime.now(),\n",
    "        'task_instance': MockTaskInstance()\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Task 1: Data Ingestion\n",
    "        print(\"\\nüìã Task: data_ingestion_task\")\n",
    "        task_data_ingestion_result = task_data_ingestion()\n",
    "        mock_context['task_instance'].xcom_data['data_ingestion_task'] = task_data_ingestion_result\n",
    "        print(f\"‚úÖ Task completed: {task_data_ingestion_result}\")\n",
    "        \n",
    "        # Task 2: Preprocessing\n",
    "        print(\"\\nüìã Task: preprocess_data_task\")\n",
    "        task_preprocess_result = task_preprocess_data()\n",
    "        mock_context['task_instance'].xcom_data['preprocess_data_task'] = task_preprocess_result\n",
    "        print(f\"‚úÖ Task completed: {task_preprocess_result}\")\n",
    "        \n",
    "        # Task 3: Model Training\n",
    "        print(\"\\nüìã Task: train_model_task\")\n",
    "        task_train_result = task_train_model()\n",
    "        mock_context['task_instance'].xcom_data['train_model_task'] = task_train_result\n",
    "        print(f\"‚úÖ Task completed: {task_train_result}\")\n",
    "        \n",
    "        # Task 4: Model Validation\n",
    "        print(\"\\nüìã Task: validate_model_task\")\n",
    "        task_validate_result = task_validate_model(**mock_context)\n",
    "        mock_context['task_instance'].xcom_data['validate_model_task'] = task_validate_result\n",
    "        print(f\"‚úÖ Task completed: {task_validate_result}\")\n",
    "        \n",
    "        print(\"\\nüéâ Simulated DAG execution successful!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Simulated DAG execution failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Mock classes for simulation\n",
    "class MockTaskInstance:\n",
    "    def __init__(self):\n",
    "        self.xcom_data = {}\n",
    "    \n",
    "    def xcom_pull(self, task_ids):\n",
    "        return self.xcom_data.get(task_ids)\n",
    "\n",
    "# Task wrapper functions (same as in the DAG)\n",
    "def task_data_ingestion():\n",
    "    \"\"\"Run data ingestion\"\"\"\n",
    "    print(\"üöÄ Starting data ingestion...\")\n",
    "    from src.data.get_data import data_ingestion\n",
    "    data_ingestion()\n",
    "    return \"data_ingestion_success\"\n",
    "\n",
    "def task_preprocess_data():\n",
    "    \"\"\"Run data preprocessing\"\"\"\n",
    "    print(\"üîÑ Starting data preprocessing...\")\n",
    "    from src.features.transform import preprocess_data\n",
    "    preprocess_data()\n",
    "    return \"preprocessing_success\"\n",
    "\n",
    "def task_train_model():\n",
    "    \"\"\"Run model training\"\"\"\n",
    "    print(\"üèãÔ∏è Starting model training...\")\n",
    "    from src.models.train_model import train_model\n",
    "    best_model, best_model_name, cv_score = train_model()\n",
    "    return {\n",
    "        \"best_model_name\": best_model_name,\n",
    "        \"cv_score\": float(cv_score),\n",
    "        \"status\": \"success\"\n",
    "    }\n",
    "\n",
    "def task_validate_model(**context):\n",
    "    \"\"\"Run model validation\"\"\"\n",
    "    print(\"üîç Starting model validation...\")\n",
    "    \n",
    "    # Get training results from previous task (simulated)\n",
    "    training_results = context['task_instance'].xcom_pull(task_ids='train_model_task')\n",
    "    print(f\"Training results: {training_results}\")\n",
    "    \n",
    "    from src.models.validate_model import validate_model\n",
    "    validation_result = validate_model()\n",
    "    \n",
    "    if not validation_result['meets_threshold']:\n",
    "        print(f\"‚ö†Ô∏è WARNING: Model accuracy below threshold!\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": validation_result['accuracy'],\n",
    "        \"meets_threshold\": validation_result['meets_threshold'],\n",
    "        \"status\": \"success\"\n",
    "    }\n",
    "\n",
    "def show_deployment_checklist():\n",
    "    \"\"\"Show checklist for Airflow deployment\"\"\"\n",
    "    \n",
    "    print(\"\\nüìã AIRFLOW DEPLOYMENT CHECKLIST\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Before deploying to Airflow, ensure:\")\n",
    "    print(\"\")\n",
    "    print(\"üìÅ File Structure:\")\n",
    "    print(\"  ‚òê dags/simple_uitf_ml_dag.py exists\")\n",
    "    print(\"  ‚òê dags/src/data/get_data.py exists\")\n",
    "    print(\"  ‚òê dags/src/features/transform.py exists\") \n",
    "    print(\"  ‚òê dags/src/models/train_model.py exists\")\n",
    "    print(\"  ‚òê dags/src/models/validate_model.py exists\")\n",
    "    print(\"\")\n",
    "    print(\"üìä Data Files:\")\n",
    "    print(\"  ‚òê data/processed/train.parquet exists\")\n",
    "    print(\"  ‚òê data/processed/test.parquet exists\")\n",
    "    print(\"  ‚òê config.yaml exists\")\n",
    "    print(\"\")\n",
    "    print(\"üê≥ Docker Setup:\")\n",
    "    print(\"  ‚òê docker-compose.yml exists\")\n",
    "    print(\"  ‚òê .env file exists\")\n",
    "    print(\"  ‚òê Docker is running\")\n",
    "    print(\"\")\n",
    "    print(\"üß™ Testing:\")\n",
    "    print(\"  ‚òê All pipeline functions tested locally\")\n",
    "    print(\"  ‚òê DAG syntax validated\")\n",
    "    print(\"  ‚òê No import errors\")\n",
    "    print(\"\")\n",
    "    print(\"üöÄ Deployment:\")\n",
    "    print(\"  1. Run: docker compose up airflow-init\")\n",
    "    print(\"  2. Run: docker compose up -d\")\n",
    "    print(\"  3. Access: http://localhost:8080\")\n",
    "    print(\"  4. Enable DAG: simple_uitf_ml_pipeline\")\n",
    "    print(\"  5. Trigger manual run\")\n",
    "    print(\"  6. Monitor in UI\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üéØ UITF ML Pipeline - Local Testing\")\n",
    "    print(\"This script tests your pipeline functions before Airflow deployment\")\n",
    "    \n",
    "    # Test individual functions\n",
    "    success = test_pipeline_functions()\n",
    "    \n",
    "    if success:\n",
    "        # Simulate Airflow execution\n",
    "        airflow_success = simulate_airflow_execution()\n",
    "        \n",
    "        if airflow_success:\n",
    "            print(\"\\nüöÄ Ready for Airflow deployment!\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è Issues found in Airflow simulation\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Fix function issues before proceeding\")\n",
    "    \n",
    "    # Show deployment checklist\n",
    "    show_deployment_checklist()\n",
    "\n",
    "# Example of running the complete pipeline in the correct order:\n",
    "\"\"\"\n",
    "PIPELINE EXECUTION ORDER:\n",
    "\n",
    "1. data_ingestion()     ‚Üí Fetches raw data\n",
    "   ‚Üì\n",
    "2. preprocess_data()    ‚Üí Cleans and prepares data  \n",
    "   ‚Üì  \n",
    "3. train_model()        ‚Üí Trains ML models, saves best model\n",
    "   ‚Üì\n",
    "4. validate_model()     ‚Üí Validates on test data, logs to MLflow\n",
    "\n",
    "Each function should handle its own file I/O and return status information.\n",
    "The DAG will orchestrate the execution and handle errors/retries.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Fernet Key:\n",
      "DaJLavur2Qzfcm1HvMIEM9tywZ1wJ8hkSYd1foXdkw4=\n",
      "\n",
      "Add this to your Docker Compose environment variables:\n",
      "AIRFLOW__CORE__FERNET_KEY: 'DaJLavur2Qzfcm1HvMIEM9tywZ1wJ8hkSYd1foXdkw4='\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"Generate a Fernet key for Airflow\"\"\"\n",
    "\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# Generate a new Fernet key\n",
    "fernet_key = Fernet.generate_key()\n",
    "print(\"Generated Fernet Key:\")\n",
    "print(fernet_key.decode())\n",
    "print(\"\\nAdd this to your Docker Compose environment variables:\")\n",
    "print(f\"AIRFLOW__CORE__FERNET_KEY: '{fernet_key.decode()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
